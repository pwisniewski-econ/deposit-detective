
@article{moro_data-driven_2014,
	title = {A data-driven approach to predict the success of bank telemarketing},
	volume = {62},
	issn = {01679236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016792361400061X},
	doi = {10.1016/j.dss.2014.03.001},
	pages = {22--31},
	journaltitle = {Decision Support Systems},
	shortjournal = {Decision Support Systems},
	author = {Moro, SÃ©rgio and Cortez, Paulo and Rita, Paulo},
	urldate = {2025-04-01},
	date = {2014-06},
	langid = {english},
}

@article{rasool_basha_study_2024,
	title = {A Study on the Effectiveness of Telemarketing in the Banking Industry},
	volume = {11},
	rights = {http://creativecommons.org/licenses/by-sa/4.0},
	issn = {2581-9402, 2321-4643},
	url = {https://shanlaxjournals.in/journals/index.php/management/article/view/8101},
	doi = {10.34293/management.v11iS1-Mar.8101},
	abstract = {This study examines the effectiveness of telemarketing in the banking industry, with a focus on identifying the optimal timing and frequency of telemarketing calls for maximizing sales conversion, measuring customer satisfaction with telemarketing calls, determining the impact of telemarketing on customer retention, and identifying factors that influence the success of telemarketing campaigns. To accomplish these objectives, a mixed-methods approach will be used, including surveys, interviews, and data analysis. The study aims to provide insights into how banks can develop more effective telemarketing strategies that generate more revenue, improve customer satisfaction, and increase customer retention. The findings of this study can be used by banks to optimize their telemarketing efforts and enhance their customer relationships.},
	pages = {134--143},
	issue = {S1-Mar},
	journaltitle = {Shanlax International Journal of Management},
	shortjournal = {management},
	author = {Rasool Basha, Rasool Basha},
	urldate = {2025-04-01},
	date = {2024-03-22},
}

@article{chernozhukov_doubledebiased_2018,
	title = {Double/debiased machine learning for treatment and structural parameters},
	volume = {21},
	rights = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
	issn = {1368-4221, 1368-423X},
	url = {https://academic.oup.com/ectj/article/21/1/C1/5056401},
	doi = {10.1111/ectj.12097},
	pages = {C1--C68},
	number = {1},
	journaltitle = {The Econometrics Journal},
	author = {Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney and Robins, James},
	urldate = {2025-04-01},
	date = {2018-02-01},
	langid = {english},
}

@article{graham_missing_2009,
	title = {Missing Data Analysis: Making It Work in the Real World},
	volume = {60},
	issn = {0066-4308, 1545-2085},
	url = {https://www.annualreviews.org/doi/10.1146/annurev.psych.58.110405.085530},
	doi = {10.1146/annurev.psych.58.110405.085530},
	shorttitle = {Missing Data Analysis},
	abstract = {This review presents a practical summary of the missing data literature, including a sketch of missing data theory and descriptions of normal-model multiple imputation ({MI}) and maximum likelihood methods. Practical missing data analysis issues are discussed, most notably the inclusion of auxiliary variables for improving power and reducing bias. Solutions are given for missing data challenges such as handling longitudinal, categorical, and clustered data with normal-model {MI}; including interactions in the missing data model; and handling large numbers of variables. The discussion of attrition and nonignorable missingness emphasizes the need for longitudinal diagnostics and for reducing the uncertainty about the missing data mechanism under attrition. Strategies suggested for reducing attrition bias include using auxiliary variables, collecting follow-up data on a sample of those initially missing, and collecting data on intent to drop out. Suggestions are given for moving forward with research on missing data and attrition.},
	pages = {549--576},
	number = {1},
	journaltitle = {Annual Review of Psychology},
	shortjournal = {Annu. Rev. Psychol.},
	author = {Graham, John W.},
	urldate = {2025-04-01},
	date = {2009-01-01},
	langid = {english},
}

@article{raghunathan_what_2004,
	title = {What Do We Do with Missing Data? Some Options for Analysis of Incomplete Data},
	volume = {25},
	issn = {0163-7525, 1545-2093},
	url = {https://www.annualreviews.org/doi/10.1146/annurev.publhealth.25.102802.124410},
	doi = {10.1146/annurev.publhealth.25.102802.124410},
	shorttitle = {What Do We Do with Missing Data?},
	abstract = {Missing data are a pervasive problem in many public health investigations. The standard approach is to restrict the analysis to subjects with complete data on the variables involved in the analysis. Estimates from such analysis can be biased, especially if the subjects who are included in the analysis are systematically different from those who were excluded in terms of one or more key variables. Severity of bias in the estimates is illustrated through a simulation study in a logistic regression setting. This article reviews three approaches for analyzing incomplete data. The first approach involves weighting subjects who are included in the analysis to compensate for those who were excluded because of missing values. The second approach is based on multiple imputation where missing values are replaced by two or more plausible values. The final approach is based on constructing the likelihood based on the incomplete observed data. The same logistic regression example is used to illustrate the basic concepts and methodology. Some software packages for analyzing incomplete data are described.},
	pages = {99--117},
	number = {1},
	journaltitle = {Annual Review of Public Health},
	shortjournal = {Annu. Rev. Public Health},
	author = {Raghunathan, Trivellore E.},
	urldate = {2025-04-01},
	date = {2004-04-01},
	langid = {english},
}

@article{bennett_how_2001,
	title = {How can I deal with missing data in my study?},
	volume = {25},
	issn = {13260200},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1326020023036488},
	doi = {10.1111/j.1467-842X.2001.tb00294.x},
	pages = {464--469},
	number = {5},
	journaltitle = {Australian and New Zealand Journal of Public Health},
	shortjournal = {Australian and New Zealand Journal of Public Health},
	author = {Bennett, Derrick A.},
	urldate = {2025-04-01},
	date = {2001-10},
	langid = {english},
}

@article{sterne_multiple_2009,
	title = {Multiple imputation for missing data in epidemiological and clinical research: potential and pitfalls},
	volume = {338},
	issn = {0959-8138, 1468-5833},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.b2393},
	doi = {10.1136/bmj.b2393},
	shorttitle = {Multiple imputation for missing data in epidemiological and clinical research},
	pages = {b2393--b2393},
	issue = {jun29 1},
	journaltitle = {{BMJ}},
	shortjournal = {{BMJ}},
	author = {Sterne, J. A C and White, I. R and Carlin, J. B and Spratt, M. and Royston, P. and Kenward, M. G and Wood, A. M and Carpenter, J. R},
	urldate = {2025-04-01},
	date = {2009-09-01},
	langid = {english},
}

@book{rubin_multiple_1987,
	edition = {1},
	title = {Multiple Imputation for Nonresponse in Surveys},
	rights = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
	isbn = {978-0-471-08705-2 978-0-470-31669-6},
	url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9780470316696},
	series = {Wiley Series in Probability and Statistics},
	publisher = {Wiley},
	author = {Rubin, Donald B.},
	urldate = {2025-04-01},
	date = {1987-06-09},
	langid = {english},
	doi = {10.1002/9780470316696},
}

@article{wager_estimation_2018,
	title = {Estimation and Inference of Heterogeneous Treatment Effects using Random Forests},
	volume = {113},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1319839},
	doi = {10.1080/01621459.2017.1319839},
	pages = {1228--1242},
	number = {523},
	journaltitle = {Journal of the American Statistical Association},
	shortjournal = {Journal of the American Statistical Association},
	author = {Wager, Stefan and Athey, Susan},
	urldate = {2025-04-01},
	date = {2018-07-03},
	langid = {english},
}

@article{hawthorne_imputing_2005,
	title = {Imputing Cross-Sectional Missing Data: Comparison of Common Techniques},
	volume = {39},
	rights = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
	issn = {0004-8674, 1440-1614},
	url = {https://journals.sagepub.com/doi/10.1080/j.1440-1614.2005.01630.x},
	doi = {10.1080/j.1440-1614.2005.01630.x},
	shorttitle = {Imputing Cross-Sectional Missing Data},
	abstract = {Objective: Increasing awareness of how missing data affects the analysis of clinical and public health interventions has led to increasing numbers of missing data procedures. There is little advice regarding which procedures should be selected under different circumstances. This paper compares six popular procedures: listwise deletion, item mean substitution, person mean substitution at two levels, regression imputation and hot deck imputation.
            Method: Using a complete dataset, each was examined under a variety of sample sizes and differing levels ofmissing data. The criteria were the true t-values for the entire sample.
            Results: The results suggest important differences. Ifmissing data are from a scale where about half the items are present, hot deck imputation or person mean substitution are best. Because person mean substitution is computationally simpler, similar in its efficiency, advocated by other researchers and more likely to be an option on statistical software packages, it is the method of choice. If the missing data are from a scale where more than half the items are missing, or with single-item measures, then hot deck imputation is recommended. The findings also showed that listwise deletion and item mean substitution performed poorly.
            Conclusions: Person mean and hot deck imputation are preferred. Since listwise deletion and item mean substitution performed poorly, yet are the most widely reported methods, the findings have broad implications.},
	pages = {583--590},
	number = {7},
	journaltitle = {Australian \& New Zealand Journal of Psychiatry},
	shortjournal = {Aust N Z J Psychiatry},
	author = {Hawthorne, Graeme and Hawthorne, Graeme and Elliott, Peter},
	urldate = {2025-04-01},
	date = {2005-07},
	langid = {english},
}

@report{berry_foundations_2021,
	location = {Cambridge, {MA}},
	title = {Foundations of Demand Estimation},
	url = {http://www.nber.org/papers/w29305.pdf},
	pages = {w29305},
	number = {w29305},
	institution = {National Bureau of Economic Research},
	author = {Berry, Steven and Haile, Philip},
	urldate = {2025-04-01},
	date = {2021-09},
	langid = {english},
	doi = {10.3386/w29305},
}

@article{blundell_initial_1998,
	title = {Initial conditions and moment restrictions in dynamic panel data models},
	volume = {87},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407698000098},
	doi = {10.1016/S0304-4076(98)00009-8},
	pages = {115--143},
	number = {1},
	journaltitle = {Journal of Econometrics},
	shortjournal = {Journal of Econometrics},
	author = {Blundell, Richard and Bond, Stephen},
	urldate = {2025-04-01},
	date = {1998-11},
	langid = {english},
}

@article{ramey_identifying_2011,
	title = {Identifying Government Spending Shocks: It's all in the Timing*},
	volume = {126},
	issn = {0033-5533, 1531-4650},
	url = {https://academic.oup.com/qje/article-lookup/doi/10.1093/qje/qjq008},
	doi = {10.1093/qje/qjq008},
	shorttitle = {Identifying Government Spending Shocks},
	pages = {1--50},
	number = {1},
	journaltitle = {The Quarterly Journal of Economics},
	author = {Ramey, Valerie A.},
	urldate = {2025-04-01},
	date = {2011-02},
	langid = {english},
}
